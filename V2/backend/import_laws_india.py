import kagglehub
import shutil
import os
import glob

def import_dataset():
    print("‚¨áÔ∏è Downloading 'Laws and Acts of India' dataset from Kaggle...")
    # Download latest version
    path = kagglehub.dataset_download("kausthubkannan/laws-and-acts-of-india")
    
    print(f"‚úÖ Downloaded to cache: {path}")
    
    # Target directory
    target_dir = "./data"
    os.makedirs(target_dir, exist_ok=True)
    
    # Move files
    # We'll look for common text formats. The structure is unknown yet.
    files = []
    for ext in ["*.txt", "*.md", "*.csv", "*.pdf"]:
        files.extend(glob.glob(os.path.join(path, ext)))
        files.extend(glob.glob(os.path.join(path, "**", ext), recursive=True))
    
    # Deduplicate
    files = list(set(files))
        
    print(f"üìÇ Found {len(files)} potential data files.")
    
    for file in files:
        # Avoid overwriting existing files with same name by prepending a prefix if needed
        # But for now let's just copy.
        filename = os.path.basename(file)
        dest = os.path.join(target_dir, f"imported_{filename}")
        print(f"üöö Moving {filename} to {target_dir}...")
        shutil.copy2(file, dest)
        
    print("‚ú® Import complete. Ready for ingestion.")

if __name__ == "__main__":
    import_dataset()
